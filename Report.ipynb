{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daa7b20c9aa57223",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Sonic Saviors: Autoencoders for Audio Noise Reduction - Project Report\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Welcome to the thrilling world of audio noise reduction with autoencoders! This project, named \"Sonic Saviors,\" delves into two innovative approaches to cleanse audio signals from unwanted noise:\n",
    "\n",
    "- **Feature-Level Denoising:** This method extracts intricate features like Mel-Frequency Cepstral Coefficients (MFCC) and Mel Spectrogram from pristine audio. We then introduce noise, train an autoencoder to reconstruct the original features, effectively removing the noise from the signal.\n",
    "\n",
    "- **Audio-Level Denoising:** In this approach, we directly manipulate the raw audio waveform by adding noise and subsequently extracting MFCC and Mel Spectrogram features. The autoencoder then works its magic to restore the clean audio waveform, employing these features.\n",
    "\n",
    "## 2. Project Structure\n",
    "\n",
    "- **README.md:** Your trusty guide through this auditory adventure.\n",
    "- **data/:** Dive into this directory to uncover the audio data used for our experiments.\n",
    "- **flickr_audio_eda.ipynb (Optional):** Embark on an auditory journey with this Jupyter Notebook containing exploratory data analysis (EDA) for audio data (if applicable).\n",
    "- **noise_audio/:** This directory houses the arsenal of scripts dedicated to audio-level denoising:\n",
    "  - **create_hybrid_file.py:** Craft hybrid files melding clean and noisy audio representations.\n",
    "  - **denoisening_dae_audio.ipynb:** Unravel the mysteries of audio-level denoising with this Jupyter Notebook.\n",
    "  - **processing_data.py (Optional):** Script to preprocess audio data for audio-level denoising (if needed).\n",
    "- **noise_features/:** This directory houses scripts related to feature-level denoising:\n",
    "  - **create_hybrid_file.py:** Generates hybrid files combining clean and noisy feature representations.\n",
    "  - **denoisening_dae_features.ipynb:** Explore feature-level denoising techniques with this Jupyter Notebook.\n",
    "  - **processing_data.py (Optional):** Script to preprocess audio data for feature-level denoising (if needed).\n",
    "- **prediction.ipynb:** Witness the prowess of our trained autoencoder models in action through this Jupyter Notebook.\n",
    "\n",
    "## 3. Autoencoder Architecture\n",
    "\n",
    "Behold the architecture defined within the `create_autoencoder` function, serving as the backbone for both models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_autoencoder(input_shape):\n",
    "    input_layer = Input(shape=input_shape)  # (148, 109, 1)\n",
    "\n",
    "    # Encoder\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # Latent space\n",
    "    latent_space = Dense(128, activation='relu')(x)\n",
    "\n",
    "    # Decoder\n",
    "    x = Dense(37 * 28 * 64, activation='relu')(latent_space)\n",
    "    x = Reshape((37, 28, 64))(x)\n",
    "    x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Cropping2D(cropping=((0, 0), (0, 1)))(x)\n",
    "    x = Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    # Correction: Pad 'SAME' to avoid information loss during upsampling\n",
    "    x = Cropping2D(cropping=((0, 0), (1, 0)))(x)\n",
    "    output_layer = Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82932505de18f80",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4. Preprocessing Parameters\n",
    "\n",
    "- **Sampling rate (sr):** 22050 Hz\n",
    "- **Fast Fourier Transform (FFT) window size (n_fft):** 2048\n",
    "- **Hop length (hop_length):** 512\n",
    "- **Number of Mel-frequency cepstral coefficients (n_mels):** 128\n",
    "- **Number of MFCC coefficients (n_mfcc):** 20\n",
    "- **Fixed length for feature vectors (fixed_length):** 55296"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ca5ba25b9c2111",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5. Noise Preprocessing Code (Audio-Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a301293e90ad94",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AudioProcessor:\n",
    "    \"\"\"\n",
    "    Class to process audio files and compute Mel spectrogram and MFCC features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sr=22050, n_fft=2048, hop_length=512, n_mels=128, n_mfcc=20, fixed_length=55296):\n",
    "        self.sr = sr\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.n_mels = n_mels\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.fixed_length = fixed_length\n",
    "        self.scal = StandardScaler()\n",
    "\n",
    "    def compute_mel_mfcc(self, audio_path: str or np.array) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Compute Mel spectrogram and MFCC features for a given audio file.\n",
    "\n",
    "        Parameters:\n",
    "            audio_path (str): Path to the audio file or raw audio data as a NumPy array.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray]: Tuple containing Mel spectrogram and MFCC features.\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(audio_path, str):\n",
    "            y, _ = librosa.load(audio_path, sr=self.sr)\n",
    "            y = librosa.util.fix_length(y, size=self.fixed_length)\n",
    "        else:\n",
    "            y = audio_path\n",
    "\n",
    "        mel = librosa.feature.melspectrogram(y=y, sr=self.sr, n_fft=self.n_fft, hop_length=self.hop_length,\n",
    "                                             n_mels=self.n_mels)\n",
    "        mfcc = librosa.feature.mfcc(S=librosa.power_to_db(mel), n_mfcc=self.n_mfcc)\n",
    "        mfcc = self.scal.fit_transform(mfcc)\n",
    "        return mel, mfcc, y\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def add_noise(audio: np.ndarray, mean=0, std=0.05) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Add Gaussian noise to audio data.\n",
    "\n",
    "        Parameters:\n",
    "            audio (np.ndarray): Input audio data.\n",
    "            mean (float): Mean of the Gaussian noise. Default is 0.1.\n",
    "            std (float): Standard deviation of the Gaussian noise. Default is 0.07.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Noisy audio data.\n",
    "        \"\"\"\n",
    "        audio_noisy = audio + np.random.normal(mean, std, audio.shape)\n",
    "        return audio_noisy\n",
    "\n",
    "\n",
    "class RepresentationSaver:\n",
    "    \"\"\"\n",
    "    Class to save hybrid representations to files.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def save_hybrid_representations(audio_paths: list, clean_save_dir: str, noisy_save_dir: str,\n",
    "                                    processor: AudioProcessor):\n",
    "        \"\"\"\n",
    "        Save hybrid representations (clean and noisy) to files.\n",
    "\n",
    "        Parameters:\n",
    "            audio_paths (list): List of paths to audio files.\n",
    "            clean_save_dir (str): Directory to save clean representations.\n",
    "            noisy_save_dir (str): Directory to save noisy representations.\n",
    "            processor (AudioProcessor): Instance of AudioProcessor class.\n",
    "        \"\"\"\n",
    "        for audio_path in tqdm(audio_paths, desc='Processing audio files'):\n",
    "            mel_clean, mfcc_clean, y = processor.compute_mel_mfcc(audio_path)\n",
    "            audio_noisy = processor.add_noise(y)\n",
    "            mel_noisy, mfcc_noisy, _ = processor.compute_mel_mfcc(audio_noisy)\n",
    "\n",
    "            filename = os.path.splitext(os.path.basename(audio_path))[0]\n",
    "\n",
    "            np.save(os.path.join(clean_save_dir, f'{filename}_hybrid_representation_clean.npy'),\n",
    "                    np.concatenate((mel_clean, mfcc_clean), axis=0))\n",
    "\n",
    "            np.save(os.path.join(noisy_save_dir, f'{filename}_hybrid_representation_noisy.npy'),\n",
    "                    np.concatenate((mel_noisy, mfcc_noisy), axis=0))\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Paths\n",
    "    audio_dir = '/mnt/c/Users/rafaj/Documents/datasets/audio-denoising-auto-encoder/data/flickr_audio/wavs'\n",
    "    train_clean_representations_dir = '/mnt/c/Users/rafaj/Documents/datasets/audio-denoising-auto-encoder/data/processed_data/noisy_audio/train/clean_hybrid_representations'\n",
    "    train_noisy_representations_dir = '/mnt/c/Users/rafaj/Documents/datasets/audio-denoising-auto-encoder/data/processed_data/noisy_audio/train/noisy_hybrid_representations'\n",
    "    test_audio_dir = '/mnt/c/Users/rafaj/Documents/datasets/audio-denoising-auto-encoder/data/processed_data/noisy_audio/test'\n",
    "\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(train_clean_representations_dir, exist_ok=True)\n",
    "    os.makedirs(train_noisy_representations_dir, exist_ok=True)\n",
    "    os.makedirs(test_audio_dir, exist_ok=True)\n",
    "\n",
    "    processor = AudioProcessor()\n",
    "    saver = RepresentationSaver()\n",
    "\n",
    "    # Split audio files into train and test sets\n",
    "    audio_paths = [os.path.join(audio_dir, file) for file in os.listdir(audio_dir) if file.endswith('.wav')]\n",
    "    np.random.shuffle(audio_paths)  # Shuffle the list of audio paths\n",
    "    num_train = int(len(audio_paths) * 0.9)  # 90% for training, 10% for testing\n",
    "    train_paths = audio_paths[:num_train]\n",
    "    test_paths = audio_paths[num_train:]\n",
    "\n",
    "    # Process and save hybrid representations for training set\n",
    "    saver.save_hybrid_representations(train_paths, train_clean_representations_dir, train_noisy_representations_dir,\n",
    "                                      processor)\n",
    "    print('Hybrid representations for training set saved successfully!')\n",
    "\n",
    "    # Copy test audio files to test directory\n",
    "    for path in test_paths:\n",
    "        filename = os.path.basename(path)\n",
    "        dest_path = os.path.join(test_audio_dir, filename)\n",
    "        shutil.copyfile(path, dest_path)\n",
    "    print('Test audio files copied successfully!')\n",
    "\n",
    "    # Save scaler\n",
    "    joblib.dump(processor.scal,\n",
    "                '/mnt/c/Users/rafaj/Documents/datasets/audio-denoising-auto-encoder/data/processed_data/noisy_audio/weights/scaler.save')\n",
    "    print('Scaler saved successfully!')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b40f7a4462731c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 6. Noise Preprocessing Code (Feature-Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bffd03d30f4c42",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AudioProcessor:\n",
    "    \"\"\"\n",
    "    Class to process audio files and compute Mel spectrogram and MFCC features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sr=22050, n_fft=2048, hop_length=512, n_mels=128, n_mfcc=20, fixed_length=55296):\n",
    "        self.sr = sr\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.n_mels = n_mels\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.fixed_length = fixed_length\n",
    "        self.scal = StandardScaler()\n",
    "\n",
    "    def compute_mel_mfcc(self, audio_path: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Compute Mel spectrogram and MFCC features for a given audio file.\n",
    "\n",
    "        Parameters:\n",
    "            audio_path (str): Path to the audio file.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray]: Tuple containing Mel spectrogram and MFCC features.\n",
    "        \"\"\"\n",
    "        y, _ = librosa.load(audio_path, sr=self.sr)\n",
    "        y = librosa.util.fix_length(y, size=self.fixed_length)\n",
    "        mel = librosa.feature.melspectrogram(y=y, sr=self.sr, n_fft=self.n_fft, hop_length=self.hop_length,\n",
    "                                             n_mels=self.n_mels)\n",
    "        mfcc = librosa.feature.mfcc(S=librosa.power_to_db(mel), n_mfcc=self.n_mfcc)\n",
    "        mfcc = self.scal.fit_transform(mfcc)\n",
    "        return mel, mfcc\n",
    "\n",
    "    @staticmethod\n",
    "    def add_noise(mel: np.ndarray, mfcc: np.ndarray, mean=0, std=0.05) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Add Gaussian noise to Mel spectrogram and MFCC features.\n",
    "\n",
    "        Parameters:\n",
    "            mel (np.ndarray): Mel spectrogram.\n",
    "            mfcc (np.ndarray): MFCC features.\n",
    "            mean (float): Mean of the Gaussian noise. Default is 0.\n",
    "            std (float): Standard deviation of the Gaussian noise. Default is 0.05.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray]: Tuple containing noisy Mel spectrogram and MFCC features.\n",
    "        \"\"\"\n",
    "        mel_noisy = mel + np.random.normal(mean, std, mel.shape)\n",
    "        mfcc_noisy = mfcc + np.random.normal(mean, std, mfcc.shape)\n",
    "        return mel_noisy, mfcc_noisy\n",
    "\n",
    "\n",
    "class RepresentationSaver:\n",
    "    \"\"\"\n",
    "    Class to save hybrid representations to files.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def save_hybrid_representations(audio_paths: list, clean_save_dir: str, noisy_save_dir: str,\n",
    "                                    processor: AudioProcessor):\n",
    "        \"\"\"\n",
    "        Save hybrid representations (clean and noisy) to files.\n",
    "\n",
    "        Parameters:\n",
    "            audio_paths (list): List of paths to audio files.\n",
    "            clean_save_dir (str): Directory to save clean representations.\n",
    "            noisy_save_dir (str): Directory to save noisy representations.\n",
    "            processor (AudioProcessor): Instance of AudioProcessor class.\n",
    "        \"\"\"\n",
    "        for audio_path in tqdm(audio_paths, desc='Processing audio files'):\n",
    "            mel_clean, mfcc_clean = processor.compute_mel_mfcc(audio_path)\n",
    "            mel_noisy, mfcc_noisy = processor.add_noise(mel_clean, mfcc_clean)\n",
    "\n",
    "            filename = os.path.splitext(os.path.basename(audio_path))[0]\n",
    "\n",
    "            np.save(os.path.join(clean_save_dir, f'{filename}_hybrid_representation_clean.npy'),\n",
    "                    np.concatenate((mel_clean, mfcc_clean), axis=0))\n",
    "\n",
    "            np.save(os.path.join(noisy_save_dir, f'{filename}_hybrid_representation_noisy.npy'),\n",
    "                    np.concatenate((mel_noisy, mfcc_noisy), axis=0))\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Paths\n",
    "    audio_dir = '/mnt/c/Users/rafaj/Documents/datasets/audio-denoising-auto-encoder/data/flickr_audio/wavs'\n",
    "    train_clean_representations_dir = '/mnt/c/Users/rafaj/Documents/datasets/audio-denoising-auto-encoder/data/processed_data/noisy_features/train/clean_hybrid_representations'\n",
    "    train_noisy_representations_dir = '/mnt/c/Users/rafaj/Documents/datasets/audio-denoising-auto-encoder/data/processed_data/noisy_features/train/noisy_hybrid_representations'\n",
    "    test_audio_dir = '/mnt/c/Users/rafaj/Documents/datasets/audio-denoising-auto-encoder/data/processed_data/noisy_features/test'\n",
    "\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(train_clean_representations_dir, exist_ok=True)\n",
    "    os.makedirs(train_noisy_representations_dir, exist_ok=True)\n",
    "    os.makedirs(test_audio_dir, exist_ok=True)\n",
    "\n",
    "    processor = AudioProcessor()\n",
    "    saver = RepresentationSaver()\n",
    "\n",
    "    # Split audio files into train and test sets\n",
    "    audio_paths = [os.path.join(audio_dir, file) for file in os.listdir(audio_dir) if file.endswith('.wav')]\n",
    "    np.random.shuffle(audio_paths)  # Shuffle the list of audio paths\n",
    "    num_train = int(len(audio_paths) * 0.9)  # 90% for training, 10% for testing\n",
    "    train_paths = audio_paths[:num_train]\n",
    "    test_paths = audio_paths[num_train:]\n",
    "\n",
    "    # Process and save hybrid representations for training set\n",
    "    saver.save_hybrid_representations(train_paths, train_clean_representations_dir, train_noisy_representations_dir,\n",
    "                                      processor)\n",
    "    print('Hybrid representations for training set saved successfully!')\n",
    "\n",
    "    # Copy test audio files to test directory\n",
    "    for path in test_paths:\n",
    "        filename = os.path.basename(path)\n",
    "        dest_path = os.path.join(test_audio_dir, filename)\n",
    "        shutil.copyfile(path, dest_path)\n",
    "    print('Test audio files copied successfully!')\n",
    "\n",
    "    # Save scaler\n",
    "    joblib.dump(processor.scal,\n",
    "                '/mnt/c/Users/rafaj/Documents/datasets/audio-denoising-auto-encoder/data/processed_data/noisy_features/weights/scaler.save')\n",
    "    print('Scaler saved successfully!')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692a1f00c58cefd2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 7. Conclusions\n",
    "\n",
    "This report has provided a comprehensive overview of the \"Sonic Saviors\" project, exploring the application of autoencoders for audio noise reduction. We've delved into the two approaches, showcased the project structure, and presented the core components like autoencoder architecture and preprocessing parameters. The provided noise preprocessing code snippets demonstrate the data preparation steps for both audio-level and feature-level denoising approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36823ba415dd365",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 8. Future Work\n",
    "\n",
    "This project lays the foundation for further exploration. We can investigate:\n",
    "\n",
    "* Hyperparameter tuning to optimize the performance of the autoencoders.\n",
    "* Different autoencoder architectures to potentially achieve better noise reduction.\n",
    "* Evaluation metrics beyond subjective listening tests to quantitatively assess the effectiveness of the denoised audio.\n",
    "\n",
    "By continuing this research, we can further refine the capabilities of autoencoders in the realm of audio noise reduction, ultimately enhancing the listening experience for everyone."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
